{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a custom BAE attack workflow step-by-step. We'll walk through the customization of each phase in the TextAttack library. Here's how you can proceed:\n",
    "\n",
    "# 1. Set Up the Environment\n",
    "Ensure you have TextAttack installed. You can install it using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textattack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Candidate Word Generation\n",
    "We'll use the WordSwapMaskedLM transformation to generate substitution and insertion candidates using a BERT-based model. Customize the number of candidates (max_candidates) or method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.transformations import WordSwapMaskedLM\n",
    "\n",
    "# Use BERT for masked language model transformations\n",
    "transformation = WordSwapMaskedLM(method=\"bae\", max_candidates=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here:\n",
    "\n",
    "method=\"bae\" ensures substitutions and insertions are generated as per the BAE algorithm.\n",
    "max_candidates=30 sets the maximum number of replacement/insertion options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Apply Constraints\n",
    "Next, we'll apply semantic and grammatical constraints. For example:\n",
    "\n",
    "Ensure replacements are semantically similar.\n",
    "Limit the percentage of words perturbed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.constraints.semantics import WordEmbeddingDistance\n",
    "from textattack.constraints.grammaticality import PartOfSpeech\n",
    "from textattack.constraints import MaxWordsPerturbed\n",
    "\n",
    "# Semantic similarity constraint\n",
    "semantic_constraint = WordEmbeddingDistance(min_cos_sim=0.8)\n",
    "\n",
    "# Grammatical constraint to ensure valid replacements\n",
    "grammatical_constraint = PartOfSpeech()\n",
    "\n",
    "# Limit the maximum number of perturbed words\n",
    "max_perturbation_constraint = MaxWordsPerturbed(max_percent=0.2)\n",
    "\n",
    "constraints = [semantic_constraint, grammatical_constraint, max_perturbation_constraint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define the Goal Function\n",
    "Set the goal function to evaluate whether the model is fooled. For example, an untargeted classification attack (simply misclassify the input):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.goal_functions import UntargetedClassification\n",
    "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
    "\n",
    "# Load a pre-trained classification model\n",
    "model = HuggingFaceModelWrapper.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Define the goal function\n",
    "goal_function = UntargetedClassification(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Combine Everything into an Attack\n",
    "Bring together the transformation, constraints, and goal function using TextAttack's attack class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.attack_recipes import Attack\n",
    "\n",
    "# Assemble the attack\n",
    "attack = Attack(transformation, constraints, goal_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Run the Attack\n",
    "You can now run the attack on a dataset or individual examples.\n",
    "\n",
    "Attack on a Custom Sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the attack on a single example\n",
    "input_sentence = [(\"This is a great product!\", 1)]  # (sentence, label)\n",
    "results = attack.attack_dataset(input_sentence)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attack on a Dataset:\n",
    "Use a HuggingFace dataset to run the attack on multiple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.datasets import HuggingFaceDataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = HuggingFaceDataset(\"imdb\", split=\"test\")\n",
    "\n",
    "# Attack the dataset\n",
    "attack_results = attack.attack_dataset(dataset)\n",
    "\n",
    "# Print some results\n",
    "for i, result in enumerate(attack_results):\n",
    "    if i > 10: break  # Print only the first 10 results\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customization Ideas\n",
    "Switch Models: Replace bert-base-uncased with other language models like roberta-base or distilbert-base-uncased.\n",
    "Modify Constraints:\n",
    "Add a similarity metric based on cosine similarity in the universal sentence encoder.\n",
    "Adjust max_percent to allow more or fewer perturbations.\n",
    "Targeted Attacks: Modify the goal_function to implement targeted attacks aiming to classify the input into a specific class.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
